[37m[36mINFO[0m[0m 06/27 14:07:38 | Command :: train_all.py exp_name --dataset PACS --data_dir /content/drive/MyDrive/code/miro/my/datasets/path --algorithm HYPERNET
Environment:
	Python: 3.10.12
	PyTorch: 2.3.0+cu121
	Torchvision: 0.18.0+cu121
	CUDA: 12.1
	CUDNN: 8906
	NumPy: 1.25.2
	PIL: 9.4.0
Args:
	algorithm: HYPERNET
	checkpoint_freq: None
	configs: []
	data_dir: /content/drive/MyDrive/code/miro/my/datasets/path
	dataset: PACS
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: None
	name: exp_name
	out_dir: train_output/PACS/240627_14-07-38_exp_name
	out_root: train_output/PACS
	prebuild_loader: False
	seed: 0
	show: False
	steps: None
	tb_freq: 10
	test_envs: None
	trial_seed: 0
	unique_name: 240627_14-07-38_exp_name
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	lr: 5e-05
	batch_size: 8
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 32
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
Dataset:
	[PACS] #envs=4, #classes=7
	env0: art_painting (#2048)
	env1: cartoon (#2344)
	env2: photo (#1670)
	env3: sketch (#3929)

[37m[36mINFO[0m[0m 06/27 14:07:38 | n_steps = 5001
[37m[36mINFO[0m[0m 06/27 14:07:38 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 06/27 14:07:38 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 06/27 14:07:38 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 06/27 14:07:38 | 
[37m[36mINFO[0m[0m 06/27 14:07:38 | Testenv name escaping te_art_painting -> te_art_painting
[37m[36mINFO[0m[0m 06/27 14:07:38 | Test envs = [0], name = te_art_painting
[37m[36mINFO[0m[0m 06/27 14:07:38 | Batch sizes for each domain: [0, 8, 8, 8] (total=24)
[37m[36mINFO[0m[0m 06/27 14:07:38 | steps-per-epoch for each domain: 234.50, 167.00, 393.00 -> min = 167.00
[37m[36mINFO[0m[0m 06/27 14:07:43 | # of params = 59977118
[37m[36mINFO[0m[0m 06/27 14:08:48 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 06/27 14:08:48 | 0.139109    0.139364    0.000000    0.143938    2961891401  0.139109    0.139364    0.149573    0.098802    0.183439    0           0.000000    2.363816    1.642978    63.909618  
[37m[36mINFO[0m[0m 06/27 14:12:43 | 0.215985    0.217604    0.000000    0.314548    5.671972    0.215985    0.217604    0.271368    0.365269    0.307006    200         1.197605    5.616672    1.027513    29.070782  
[37m[36mINFO[0m[0m 06/27 14:15:38 | 0.178768    0.185819    0.000000    0.364395    4.220485    0.178768    0.185819    0.348291    0.425150    0.319745    400         2.395210    4.311021    0.735103    27.496586  
[37m[36mINFO[0m[0m 06/27 14:17:57 | 0.158023    0.154034    0.000000    0.352995    3.404703    0.158023    0.154034    0.286325    0.389222    0.383439    600         3.592814    3.626991    0.554657    28.984839  
[37m[36mINFO[0m[0m 06/27 14:20:12 | 0.140329    0.158924    0.000000    0.367661    3.459374    0.140329    0.158924    0.320513    0.395210    0.387261    800         4.790419    3.522156    0.532157    28.506872  
[37m[36mINFO[0m[0m 06/27 14:22:29 | 0.217206    0.210269    0.000000    0.420156    3.368634    0.217206    0.210269    0.384615    0.449102    0.426752    1000        5.988024    3.558438    0.538284    28.747545  
[37m[36mINFO[0m[0m 06/27 14:24:46 | 0.253203    0.259169    0.000000    0.471715    2.330218    0.253203    0.259169    0.393162    0.574850    0.447134    1200        7.185629    3.384991    0.542320    28.621417  
[37m[36mINFO[0m[0m 06/27 14:27:05 | 0.180598    0.154034    0.000000    0.417085    2.845463    0.180598    0.154034    0.350427    0.497006    0.403822    1400        8.383234    3.095309    0.552351    28.292682  
[37m[36mINFO[0m[0m 06/27 14:29:25 | 0.254423    0.239609    0.000000    0.423574    2.849612    0.254423    0.239609    0.356838    0.482036    0.431847    1600        9.580838    3.052052    0.557491    29.107846  
[37m[36mINFO[0m[0m 06/27 14:31:44 | 0.264796    0.246944    0.000000    0.451583    2.462562    0.264796    0.246944    0.408120    0.547904    0.398726    1800        10.778443   2.773769    0.558684    27.139066  
[37m[36mINFO[0m[0m 06/27 14:34:12 | 0.247712    0.210269    0.000000    0.462823    2.815872    0.247712    0.210269    0.405983    0.514970    0.467516    2000        11.976048   2.788478    0.593648    28.703995  
[37m[36mINFO[0m[0m 06/27 14:36:30 | 0.222697    0.195599    0.000000    0.459798    2.406330    0.222697    0.195599    0.403846    0.553892    0.421656    2200        13.173653   2.823095    0.547458    28.366423  
[37m[36mINFO[0m[0m 06/27 14:38:48 | 0.190970    0.200489    0.000000    0.357549    3.438746    0.190970    0.200489    0.326923    0.422156    0.323567    2400        14.371257   2.850730    0.548701    28.420586  
[37m[36mINFO[0m[0m 06/27 14:41:07 | 0.209274    0.176039    0.000000    0.431232    2.450470    0.209274    0.176039    0.367521    0.479042    0.447134    2600        15.568862   2.412884    0.554340    28.001231  
[37m[36mINFO[0m[0m 06/27 14:43:26 | 0.241611    0.220049    0.000000    0.479014    2.045286    0.241611    0.220049    0.408120    0.535928    0.492994    2800        16.766467   2.587859    0.554555    28.321292  
[37m[36mINFO[0m[0m 06/27 14:45:45 | 0.215985    0.190709    0.000000    0.444217    2.470617    0.215985    0.190709    0.341880    0.544910    0.445860    3000        17.964072   2.291989    0.551358    28.850614  
[37m[36mINFO[0m[0m 06/27 14:48:05 | 0.237340    0.244499    0.000000    0.504630    1.798673    0.237340    0.244499    0.452991    0.553892    0.507006    3200        19.161677   2.320397    0.554921    28.852149  
[37m[36mINFO[0m[0m 06/27 14:50:24 | 0.241611    0.222494    0.000000    0.466811    2.182263    0.241611    0.222494    0.420940    0.511976    0.467516    3400        20.359281   2.074898    0.550464    28.578724  
[37m[36mINFO[0m[0m 06/27 14:52:43 | 0.179378    0.193154    0.000000    0.448386    2.328642    0.179378    0.193154    0.382479    0.535928    0.426752    3600        21.556886   2.062807    0.554183    28.755271  
[37m[36mINFO[0m[0m 06/27 14:55:02 | 0.209274    0.212714    0.000000    0.522419    1.690284    0.209274    0.212714    0.491453    0.559880    0.515924    3800        22.754491   1.990767    0.551501    28.698808  
[37m[36mINFO[0m[0m 06/27 14:57:21 | 0.264796    0.237164    0.000000    0.518413    1.792556    0.264796    0.237164    0.485043    0.547904    0.522293    4000        23.952096   1.996591    0.553187    28.121926  
[37m[36mINFO[0m[0m 06/27 14:59:41 | 0.250763    0.215159    0.000000    0.498736    1.750119    0.250763    0.215159    0.446581    0.580838    0.468790    4200        25.149701   1.893629    0.553403    29.042895  
[37m[36mINFO[0m[0m 06/27 15:01:59 | 0.248932    0.246944    0.000000    0.511977    1.494571    0.248932    0.246944    0.504274    0.502994    0.528662    4400        26.347305   1.732629    0.555295    27.718491  
[37m[36mINFO[0m[0m 06/27 15:04:20 | 0.216595    0.185819    0.000000    0.487734    1.620846    0.216595    0.185819    0.414530    0.565868    0.482803    4600        27.544910   1.627789    0.558187    29.248504  
[37m[36mINFO[0m[0m 06/27 15:06:40 | 0.264796    0.229829    0.000000    0.516177    1.510423    0.264796    0.229829    0.491453    0.553892    0.503185    4800        28.742515   1.552673    0.553651    28.767224  
[37m[36mINFO[0m[0m 06/27 15:09:00 | 0.239170    0.212714    0.000000    0.528664    1.477028    0.239170    0.212714    0.472222    0.583832    0.529936    5000        29.940120   1.495394    0.554960    29.023515  
[37m[36mINFO[0m[0m 06/27 15:09:00 | ---
[37m[36mINFO[0m[0m 06/27 15:09:00 | training-domain validation = 23.917%
[37m[36mINFO[0m[0m 06/27 15:09:00 | 
[37m[36mINFO[0m[0m 06/27 15:09:00 | Testenv name escaping te_cartoon -> te_cartoon
[37m[36mINFO[0m[0m 06/27 15:09:00 | Test envs = [1], name = te_cartoon
[37m[36mINFO[0m[0m 06/27 15:09:00 | Batch sizes for each domain: [8, 0, 8, 8] (total=24)
[37m[36mINFO[0m[0m 06/27 15:09:00 | steps-per-epoch for each domain: 204.88, 167.00, 393.00 -> min = 167.00
[37m[36mINFO[0m[0m 06/27 15:09:04 | # of params = 59977118
[37m[36mINFO[0m[0m 06/27 15:09:36 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_in     env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 06/27 15:09:36 | 0.163113    0.166667    0.000000    0.143712    1487364778  0.136919    0.163113    0.166667    0.110778    0.183439    0           0.000000    1.954464    0.520800    31.209940  
[37m[36mINFO[0m[0m 06/27 15:11:59 | 0.235608    0.264957    0.000000    0.265439    6.079304    0.224939    0.235608    0.264957    0.329341    0.242038    200         1.197605    5.997400    0.565583    30.575238  
[37m[36mINFO[0m[0m 06/27 15:14:21 | 0.209488    0.224359    0.000000    0.339105    4.108509    0.246944    0.209488    0.224359    0.425150    0.345223    400         2.395210    4.917181    0.557658    29.921179  
[37m[36mINFO[0m[0m 06/27 15:16:42 | 0.232942    0.258547    0.000000    0.332832    3.717985    0.237164    0.232942    0.258547    0.467066    0.294268    600         3.592814    4.293571    0.559407    29.585755  
[37m[36mINFO[0m[0m 06/27 15:19:04 | 0.200426    0.166667    0.000000    0.379992    3.062387    0.264059    0.200426    0.166667    0.458084    0.417834    800         4.790419    4.028954    0.556279    30.477553  
[37m[36mINFO[0m[0m 06/27 15:21:27 | 0.190832    0.198718    0.000000    0.258245    4.942951    0.144254    0.190832    0.198718    0.281437    0.349045    1000        5.988024    4.050047    0.564720    30.454391  
[37m[36mINFO[0m[0m 06/27 15:23:50 | 0.221215    0.211538    0.000000    0.359832    5.186089    0.286064    0.221215    0.211538    0.443114    0.350318    1200        7.185629    3.326633    0.558074    31.024232  
[37m[36mINFO[0m[0m 06/27 15:26:14 | 0.287846    0.297009    0.000000    0.408188    2.501466    0.264059    0.287846    0.297009    0.470060    0.490446    1400        8.383234    3.764935    0.567506    30.093029  

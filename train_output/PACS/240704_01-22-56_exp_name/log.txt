[37m[36mINFO[0m[0m 07/04 01:22:57 | Command :: train_all.py exp_name --dataset PACS --data_dir /content/drive/MyDrive/code/miro/my/datasets/path --algorithm HYPERNET
Environment:
	Python: 3.10.12
	PyTorch: 2.3.0+cu121
	Torchvision: 0.18.0+cu121
	CUDA: 12.1
	CUDNN: 8906
	NumPy: 1.25.2
	PIL: 9.4.0
Args:
	algorithm: HYPERNET
	checkpoint_freq: None
	configs: []
	data_dir: /content/drive/MyDrive/code/miro/my/datasets/path
	dataset: PACS
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: None
	name: exp_name
	out_dir: train_output/PACS/240704_01-22-56_exp_name
	out_root: train_output/PACS
	prebuild_loader: False
	seed: 0
	show: False
	steps: None
	tb_freq: 10
	test_envs: None
	trial_seed: 0
	unique_name: 240704_01-22-56_exp_name
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	resnet_dropout: 0.0
	class_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	lr: 5e-05
	batch_size: 16
	weight_decay: 0.0
	swad: False
	swad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 32
	model: resnet50
	feat_layers: stem_block
	ld: 0.1
	lr_mult: 10.0
Dataset:
	[PACS] #envs=4, #classes=7
	env0: art_painting (#2048)
	env1: cartoon (#2344)
	env2: photo (#1670)
	env3: sketch (#3929)

[37m[36mINFO[0m[0m 07/04 01:22:57 | n_steps = 5001
[37m[36mINFO[0m[0m 07/04 01:22:57 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 07/04 01:22:57 | n_steps is updated to 5001 => 5001 for checkpointing
[37m[36mINFO[0m[0m 07/04 01:22:57 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 07/04 01:22:57 | 
[37m[36mINFO[0m[0m 07/04 01:22:57 | Testenv name escaping te_art_painting -> te_art_painting
[37m[36mINFO[0m[0m 07/04 01:22:57 | Test envs = [0], name = te_art_painting
[37m[36mINFO[0m[0m 07/04 01:22:57 | Batch sizes for each domain: [0, 16, 16, 16] (total=48)
[37m[36mINFO[0m[0m 07/04 01:22:57 | steps-per-epoch for each domain: 117.25, 83.50, 196.50 -> min = 83.50
[37m[36mINFO[0m[0m 07/04 01:22:59 | # of params = 12942807
[37m[36mINFO[0m[0m 07/04 01:24:55 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 07/04 01:24:55 | 0.115314    0.161369    0.000000    0.181287    1409710819  0.115314    0.161369    0.220085    0.146707    0.177070    0           0.000000    2.199059    2.977987    112.918395 
[37m[36mINFO[0m[0m 07/04 01:31:29 | 0.136059    0.151589    0.000000    0.303589    3.821156    0.136059    0.151589    0.247863    0.302395    0.360510    200         2.395210    4.754251    1.819315    30.191797  
[37m[36mINFO[0m[0m 07/04 01:35:22 | 0.205003    0.180929    0.000000    0.435064    2.185534    0.205003    0.180929    0.341880    0.505988    0.457325    400         4.790419    3.073761    1.015635    29.797861  
[37m[36mINFO[0m[0m 07/04 01:39:11 | 0.287370    0.244499    0.000000    0.405487    2.898246    0.287370    0.244499    0.341880    0.449102    0.425478    600         7.185629    3.166026    1.003665    29.100375  
[37m[36mINFO[0m[0m 07/04 01:43:01 | 0.189140    0.205379    0.000000    0.397577    3.117207    0.189140    0.205379    0.363248    0.437126    0.392357    800         9.580838    2.918185    1.006606    28.592751  
[37m[36mINFO[0m[0m 07/04 01:46:53 | 0.229408    0.217604    0.000000    0.415377    2.888189    0.229408    0.217604    0.352564    0.491018    0.402548    1000        11.976048   2.752353    1.012709    28.653036  
[37m[36mINFO[0m[0m 07/04 01:50:44 | 0.215375    0.212714    0.000000    0.487101    2.346177    0.215375    0.212714    0.427350    0.526946    0.507006    1200        14.371257   2.504908    1.012343    28.658282  
[37m[36mINFO[0m[0m 07/04 01:54:35 | 0.236730    0.232274    0.000000    0.503566    1.980859    0.236730    0.232274    0.401709    0.568862    0.540127    1400        16.766467   2.459935    1.013931    28.497242  
[37m[36mINFO[0m[0m 07/04 01:58:26 | 0.232459    0.232274    0.000000    0.522522    2.543626    0.232459    0.232274    0.435897    0.592814    0.538854    1600        19.161677   2.374600    1.012234    28.888905  
[37m[36mINFO[0m[0m 07/04 02:02:18 | 0.236120    0.266504    0.000000    0.527462    1.865624    0.236120    0.266504    0.446581    0.577844    0.557962    1800        21.556886   2.353085    1.011643    29.182871  
[37m[36mINFO[0m[0m 07/04 02:06:09 | 0.226968    0.234719    0.000000    0.509237    1.927675    0.226968    0.234719    0.429487    0.547904    0.550318    2000        23.952096   2.202707    1.011205    29.352012  
[37m[36mINFO[0m[0m 07/04 02:09:59 | 0.242831    0.239609    0.000000    0.484111    1.932327    0.242831    0.239609    0.412393    0.532934    0.507006    2200        26.347305   2.200191    1.006335    28.304136  
[37m[36mINFO[0m[0m 07/04 02:13:51 | 0.248932    0.254279    0.000000    0.513867    1.937624    0.248932    0.254279    0.429487    0.589820    0.522293    2400        28.742515   2.138482    1.013756    29.309929  
[37m[36mINFO[0m[0m 07/04 02:17:42 | 0.243441    0.222494    0.000000    0.522365    1.814565    0.243441    0.222494    0.442308    0.580838    0.543949    2600        31.137725   1.896127    1.011647    28.970377  
[37m[36mINFO[0m[0m 07/04 02:21:35 | 0.220256    0.193154    0.000000    0.530951    1.791148    0.220256    0.193154    0.482906    0.583832    0.526115    2800        33.532934   1.773508    1.015213    29.822158  
[37m[36mINFO[0m[0m 07/04 02:25:26 | 0.249542    0.237164    0.000000    0.543466    1.768890    0.249542    0.237164    0.452991    0.634731    0.542675    3000        35.928144   1.818377    1.008381    28.779232  
[37m[36mINFO[0m[0m 07/04 02:29:18 | 0.275168    0.273839    0.000000    0.539718    1.680400    0.275168    0.273839    0.478632    0.583832    0.556688    3200        38.323353   1.815426    1.012150    29.814973  
[37m[36mINFO[0m[0m 07/04 02:33:09 | 0.251983    0.249389    0.000000    0.553406    1.575891    0.251983    0.249389    0.485043    0.619760    0.555414    3400        40.718563   1.743765    1.013575    27.713527  
[37m[36mINFO[0m[0m 07/04 02:36:58 | 0.288591    0.268949    0.000000    0.497641    1.852226    0.288591    0.268949    0.420940    0.559880    0.512102    3600        43.113772   1.683010    1.004542    28.966602  
[37m[36mINFO[0m[0m 07/04 02:40:49 | 0.249542    0.242054    0.000000    0.553870    1.583554    0.249542    0.242054    0.476496    0.643713    0.541401    3800        45.508982   1.677038    1.006599    28.788962  
[37m[36mINFO[0m[0m 07/04 02:44:41 | 0.243441    0.220049    0.000000    0.553653    1.825454    0.243441    0.220049    0.467949    0.619760    0.573248    4000        47.904192   1.545615    1.016472    29.377217  
[37m[36mINFO[0m[0m 07/04 02:48:33 | 0.206223    0.193154    0.000000    0.519633    1.654702    0.206223    0.193154    0.459402    0.547904    0.551592    4200        50.299401   1.563993    1.015023    28.403758  
[37m[36mINFO[0m[0m 07/04 02:52:23 | 0.244661    0.227384    0.000000    0.547359    1.450096    0.244661    0.227384    0.474359    0.586826    0.580892    4400        52.694611   1.484346    1.014180    27.988244  
[37m[36mINFO[0m[0m 07/04 02:56:15 | 0.276388    0.244499    0.000000    0.545691    1.433474    0.276388    0.244499    0.444444    0.625749    0.566879    4600        55.089820   1.438521    1.009065    29.477246  
[37m[36mINFO[0m[0m 07/04 03:00:09 | 0.292251    0.261614    0.000000    0.546082    1.398787    0.292251    0.261614    0.442308    0.613772    0.582166    4800        57.485030   1.348059    1.023445    29.392368  
[37m[36mINFO[0m[0m 07/04 03:04:02 | 0.259304    0.217604    0.000000    0.579503    1.258641    0.259304    0.217604    0.517094    0.613772    0.607643    5000        59.880240   1.311546    1.017659    29.796491  
[37m[36mINFO[0m[0m 07/04 03:04:02 | ---
[37m[36mINFO[0m[0m 07/04 03:04:02 | training-domain validation = 25.930%
[37m[36mINFO[0m[0m 07/04 03:04:02 | 
[37m[36mINFO[0m[0m 07/04 03:04:03 | Testenv name escaping te_cartoon -> te_cartoon
[37m[36mINFO[0m[0m 07/04 03:04:03 | Test envs = [1], name = te_cartoon
[37m[36mINFO[0m[0m 07/04 03:04:03 | Batch sizes for each domain: [16, 0, 16, 16] (total=48)
[37m[36mINFO[0m[0m 07/04 03:04:03 | steps-per-epoch for each domain: 102.44, 83.50, 196.50 -> min = 83.50
[37m[36mINFO[0m[0m 07/04 03:04:03 | # of params = 12942807
[37m[36mINFO[0m[0m 07/04 03:04:40 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_in     env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 07/04 03:04:40 | 0.170043    0.149573    0.000000    0.163993    1515130203  0.176039    0.170043    0.149573    0.119760    0.196178    0           0.000000    2.188471    3.029209    33.695072  
[37m[36mINFO[0m[0m 07/04 03:08:35 | 0.206290    0.198718    0.000000    0.338849    3.108729    0.227384    0.206290    0.198718    0.440120    0.349045    200         2.395210    5.085496    1.019990    31.223492  
[37m[36mINFO[0m[0m 07/04 03:12:31 | 0.245203    0.239316    0.000000    0.372541    3.429556    0.220049    0.245203    0.239316    0.458084    0.439490    400         4.790419    3.615496    1.018756    32.127666  
[37m[36mINFO[0m[0m 07/04 03:16:26 | 0.301173    0.324786    0.000000    0.338904    4.443121    0.237164    0.301173    0.324786    0.461078    0.318471    600         7.185629    3.327320    1.022965    30.606726  
[37m[36mINFO[0m[0m 07/04 03:20:22 | 0.228145    0.241453    0.000000    0.371753    3.155675    0.232274    0.228145    0.241453    0.437126    0.445860    800         9.580838    3.213964    1.021354    31.716698  
[37m[36mINFO[0m[0m 07/04 03:24:19 | 0.305437    0.318376    0.000000    0.372146    3.907503    0.234719    0.305437    0.318376    0.497006    0.384713    1000        11.976048   3.089935    1.028382    31.128821  
[37m[36mINFO[0m[0m 07/04 03:28:16 | 0.242004    0.290598    0.000000    0.412856    2.352511    0.205379    0.242004    0.290598    0.538922    0.494268    1200        14.371257   2.725979    1.025386    31.263586  
[37m[36mINFO[0m[0m 07/04 03:32:11 | 0.257463    0.260684    0.000000    0.388121    2.476396    0.237164    0.257463    0.260684    0.502994    0.424204    1400        16.766467   2.532080    1.023573    30.636474  
[37m[36mINFO[0m[0m 07/04 03:36:08 | 0.248934    0.264957    0.000000    0.405364    2.939640    0.256724    0.248934    0.264957    0.547904    0.411465    1600        19.161677   2.512930    1.023926    31.754564  
[37m[36mINFO[0m[0m 07/04 03:40:01 | 0.304904    0.326923    0.000000    0.431577    2.046009    0.254279    0.304904    0.326923    0.544910    0.495541    1800        21.556886   2.505148    1.018674    29.513852  
[37m[36mINFO[0m[0m 07/04 03:43:53 | 0.276652    0.294872    0.000000    0.413486    2.240899    0.254279    0.276652    0.294872    0.497006    0.489172    2000        23.952096   2.324472    1.008560    30.638081  
[37m[36mINFO[0m[0m 07/04 03:47:46 | 0.250533    0.258547    0.000000    0.455169    2.013437    0.312958    0.250533    0.258547    0.514970    0.537580    2200        26.347305   2.113593    1.013375    30.145997  
[37m[36mINFO[0m[0m 07/04 03:51:39 | 0.260661    0.273504    0.000000    0.423236    2.433199    0.268949    0.260661    0.273504    0.458084    0.542675    2400        28.742515   2.152986    1.013146    30.741520  
[37m[36mINFO[0m[0m 07/04 03:55:34 | 0.251599    0.258547    0.000000    0.463078    1.980677    0.283619    0.251599    0.258547    0.571856    0.533758    2600        31.137725   2.196883    1.020489    30.626055  
[37m[36mINFO[0m[0m 07/04 03:59:28 | 0.268657    0.267094    0.000000    0.447388    2.269896    0.283619    0.268657    0.267094    0.580838    0.477707    2800        33.532934   2.075945    1.014488    31.140472  
[37m[36mINFO[0m[0m 07/04 04:03:23 | 0.301173    0.352564    0.000000    0.471403    1.896636    0.322738    0.301173    0.352564    0.553892    0.537580    3000        35.928144   1.911549    1.023122    30.197865  
[37m[36mINFO[0m[0m 07/04 04:07:18 | 0.291578    0.337607    0.000000    0.436352    1.847364    0.286064    0.291578    0.337607    0.479042    0.543949    3200        38.323353   1.924423    1.015554    31.358146  
[37m[36mINFO[0m[0m 07/04 04:11:11 | 0.322495    0.346154    0.000000    0.448815    1.961743    0.266504    0.322495    0.346154    0.544910    0.535032    3400        40.718563   1.837056    1.014108    30.223769  
[37m[36mINFO[0m[0m 07/04 04:15:03 | 0.352878    0.391026    0.000000    0.462613    1.650223    0.322738    0.352878    0.391026    0.547904    0.517197    3600        43.113772   1.705118    1.011830    29.769822  
[37m[36mINFO[0m[0m 07/04 04:18:58 | 0.295842    0.341880    0.000000    0.444487    1.778320    0.286064    0.295842    0.341880    0.565868    0.481529    3800        45.508982   1.691584    1.024136    30.533170  
[37m[36mINFO[0m[0m 07/04 04:22:53 | 0.300640    0.320513    0.000000    0.490968    1.500159    0.312958    0.300640    0.320513    0.568862    0.591083    4000        47.904192   1.680912    1.015360    32.020685  
[37m[36mINFO[0m[0m 07/04 04:26:47 | 0.312367    0.361111    0.000000    0.498305    1.501098    0.354523    0.312367    0.361111    0.565868    0.574522    4200        50.299401   1.625236    1.016542    30.686355  
[37m[36mINFO[0m[0m 07/04 04:30:43 | 0.351279    0.358974    0.000000    0.474795    1.682232    0.308068    0.351279    0.358974    0.583832    0.532484    4400        52.694611   1.640135    1.022761    31.017906  
[37m[36mINFO[0m[0m 07/04 04:34:37 | 0.334755    0.333333    0.000000    0.478609    1.480431    0.293399    0.334755    0.333333    0.553892    0.588535    4600        55.089820   1.559347    1.015327    30.986788  
[37m[36mINFO[0m[0m 07/04 04:38:33 | 0.272921    0.271368    0.000000    0.473950    1.560754    0.334963    0.272921    0.271368    0.565868    0.521019    4800        57.485030   1.492479    1.023489    31.128827  
[37m[36mINFO[0m[0m 07/04 04:42:27 | 0.335288    0.352564    0.000000    0.473736    1.582598    0.251834    0.335288    0.352564    0.580838    0.588535    5000        59.880240   1.503497    1.017383    30.770557  
[37m[36mINFO[0m[0m 07/04 04:42:27 | ---
[37m[36mINFO[0m[0m 07/04 04:42:27 | training-domain validation = 31.237%
[37m[36mINFO[0m[0m 07/04 04:42:27 | 
[37m[36mINFO[0m[0m 07/04 04:42:27 | Testenv name escaping te_photo -> te_photo
[37m[36mINFO[0m[0m 07/04 04:42:27 | Test envs = [2], name = te_photo
[37m[36mINFO[0m[0m 07/04 04:42:27 | Batch sizes for each domain: [16, 16, 0, 16] (total=48)
[37m[36mINFO[0m[0m 07/04 04:42:27 | steps-per-epoch for each domain: 102.44, 117.25, 196.50 -> min = 102.44
[37m[36mINFO[0m[0m 07/04 04:42:28 | # of params = 12942807
[37m[36mINFO[0m[0m 07/04 04:42:59 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_in     env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 07/04 04:42:59 | 0.111527    0.119760    0.000000    0.173930    2952061734  0.176039    0.149573    0.111527    0.119760    0.196178    0           0.000000    2.123261    4.772702    26.139550  
[37m[36mINFO[0m[0m 07/04 04:46:48 | 0.151198    0.128743    0.000000    0.234781    4.746157    0.163814    0.262821    0.151198    0.128743    0.277707    200         1.952410    5.114066    1.016942    25.158205  
